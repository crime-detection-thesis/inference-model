services:
  inference-model:
    container_name: inference-model
    build:
      context: .
      dockerfile: prod.dockerfile
    ports:
      - "8003:8003"
    env_file:
      - .env
    restart: always
